manifest:
  version: "0.1.3"
  schema: https://a2as.org/cert/schema
  subject:
    name: notneelpatel/cityagent
    source: https://github.com/notneelpatel/cityagent
    branch: main
    commit: "7b6567b4"
    scope: [backend/src/rag_pipeline/vectorize_excel.py, backend/src/rag_pipeline/vectorize_pdf.py, backend/src/ai_api_selector.py,
      backend/src/city_agent/__init__.py, backend/src/city_agent/agent.py, backend/src/rag_pipeline/vector.py]
  issued:
    by: A2AS.org
    at: '2026-02-11T16:53:35Z'
    url: https://a2as.org/certified/agents/notneelpatel/cityagent
  signatures:
    digest: sha256:wQyW3xBbndbrY_-_6_nkMV7w16nsRHZirPnb-c88Wg4
    key: ed25519:ALuYV8CNUlSqI7Sm7OvLfg1xtSdMwMwpR_qkeoTpFgM
    sig: ed25519:BxbD9QrOBNHtgH9duA6BzGRaksOJ7nQdD1mYp3pccsYcCOqTv6J9WC67YCIXBhSSN2Upp9Y_-HCcthMocRl-DA

agents:
  agent.0:
    type: instance
    models: [ai_api]
    params:
      name: Excel_Vectorization_Agent
      instruction: ['Task: Classify tabular column names into two disjoint sets: ''page_content'' and ''metadata''.', 'Output
          Format:', 'Return only a valid minified JSON object:', 'Inputs:', 'headers: list of column names', 'sample_row:
          list of small row objects for context', Definitions, 'page_content: Columns containing visible or descriptive text
          that belongs in a page''s body (titles, summaries, paragraphs, captions, human-readable descriptions, bullet-like
          text).', 'metadata: Columns describing or organizing content (IDs, slugs, URLs, timestamps, authors, categories,
          tags, booleans, numeric codes, languages, statuses, counts, etc.).', Rules, 1. Only include English headers. Ignore
          non-English or mixed-language ones entirely., 2. Use only the provided headers; never invent new ones., 3. Each
          header belongs to exactly one set (no overlap)., '4. Infer meaning from ''sample_rows'':', '* Long free text → ''page_content''',
        '* Titles, headlines → ''page_content''', '* IDs, GUIDs, numeric keys, booleans, enums, short codes, emails, phones
          → ''metadata''', '* URLs, slugs, filenames, file paths, image links → ''metadata''', '* Dates, times, timestamps
          → ''metadata''', '* Author, editor, owner, source, license → ''metadata''', '* Category, tag, topic, language, locale
          → ''metadata''', '* If uncertain, prefer ''metadata'' for structural or administrative fields.', 5. Keep header
          text exactly as given., '6. If a list would be empty, return an empty array.', '7. Output only valid JSON. No text,
          comments, or formatting beyond that.', 8. Use double quotes for all strings and property names (JSON standard).,
        '9. Use string keys for indices. Example: "0" not 0.', Examples, 'Example A:', Example B, Example C, 'headers: {0:"Résumé",1:"Titre",2:"Lien",3:"Date",4:"Notes"}->',
        '{"page_content":{4:"Notes"],"metadata":[3:"Date"}}']
      instance: agent
  agent.1:
    type: instance
    models: [ai_api]
    params:
      name: PDF_Vectorization_Agent
      instruction: [You are a document processing assistant for asset management reports., Your goal is to transform provided
          text into a structured JSON format., '### Tasks:', '- Translate all visible data tables into standard Markdown syntax.',
        '- Extract only English text content.', '- Identify and list specific figures, percentages, and dates in the metrics
          field.', '- Provide a summary of the current section in the context header.', '- Use the following classifications:',
        '- Service Area: (e.g., Transportation, Water, Facilities)', '- Data Type: (e.g., Financial, Condition, Inventory)',
        '- Topic: A brief subject label.', '### Schema Requirements:', Ensure the output follows the keys and structure provided
          in the JSON schema section., 'STRICT REQUIREMENT: Return ONLY a valid JSON object matching this schema:', '{json.dumps}']
      include_contents: none
      instance: agent
  data_fetcher:
    type: instance
    models: ['gpt-oss:latest']
    tools: [search_data]
    params:
      name: DataFetcher
      instruction: ['You are part of the larger CityAgent framework. Your task is to fetch relevant data based on a user''s
          query. If no relevant data is found or the query is inappropriate given the context of providing an answer relating
          to the City of Ottawa asset management, respond with a string that says ''no data found''. Only provide raw data
          output that is relevant to the query. With the raw data output, always include the filename and last_updated']
      output_key: raw_data
  location_agent:
    type: instance
    models: ['gpt-oss:latest']
    params:
      name: LocationAgent
      instruction: [return none]
      output_key: location_context
  math_analyst:
    type: instance
    models: ['gpt-oss:latest']
    params:
      name: MathAnalyst
      instruction: [return none]
      output_key: math_results
  output_agent:
    type: instance
    models: ['gpt-oss:latest']
    params:
      name: OutputAgent
      instruction: ['You are part of the larger CityAgent framework. Format the following response into a clean, professional
          response', 'Use the following format for your answers, if there are no sources, still include an empty sources list.:',
        'ONLY output in minified JSON format as follows:', '{', '"response": "<final formatted answer here>",', '"sources":
          [{"filename": "<filename>",', '"lastUpdated": "2026-10-01",', '"href": "#",', '}]', '}']
      output_key: final_response
  reasoner_agent:
    type: instance
    models: ['gpt-oss:latest']
    params:
      name: Reasoner
      instruction: ['You are part of the larger CityAgent framework. Using the data in {{raw_data}},', 'construct a logical
          response to the user''s query. If the data is insufficient or irrelevant, state that clearly.', Ensure you cite
          specific data points using the metadata 'filename' and 'last_updated'. DO NOT MENTION PREVIOUS STEPS MADE BY OTHER
          AGENTS]
      output_key: reasoning_output
  root_agent.0:
    type: instance
    models: [gemini-2.5-flash]
    params:
      name: CityAgent_Orchestrator
      data_fetcher: data_fetcher
      location_agent: location_agent
      math_analyst: math_analyst
      reasoner_agent: reasoner_agent
      validator_agent: validator_agent
      output_agent: output_agent
      instance: root_agent
  root_agent.1:
    type: instance
    models: [gemini-2.5-flash]
    params:
      class: OrchestratorAgent
      base: BaseAgent
      name: name
      data_fetcher: data_fetcher
      location_agent: location_agent
      math_analyst: math_analyst
      reasoner_agent: reasoner_agent
      validator_agent: validator_agent
      output_agent: output_agent
      sub_agents: [sub_agents_list]
      instance: root_agent
  validator_agent:
    type: instance
    models: ['gpt-oss:latest']
    params:
      name: ValidatorAgent
      instruction: [Set the validation_result to VALID]
      output_key: validation_result

models:
  ai_api:
    type: literal
    agents: [agent.0, agent.1]
  gemini-2.5-flash:
    type: default
    agents: [root_agent.0, root_agent.1]
  gpt-oss:latest:
    type: literal
    agents: [data_fetcher, reasoner_agent, output_agent, validator_agent, location_agent, math_analyst]
    params:
      alias: ['openai/gpt-oss:latest']

tools:
  search_data:
    type: function
    agents: [data_fetcher]
    params:
      description: |-
        Offload the (potentially) blocking retriever call to a thread so the
        async event loop isn't blocked when this tool is used inside an async
        agent/runtime.

imports:
  AsyncGenerator: typing.AsyncGenerator
  asyncio: asyncio
  AzureOpenAIEmbeddings: langchain_openai.AzureOpenAIEmbeddings
  BaseAgent: google.adk.agents.BaseAgent
  Chroma: langchain_chroma.Chroma
  ctime: time.ctime
  Document: langchain_core.documents.Document
  Enum: enum.Enum
  Event: google.adk.events.Event
  get_agent_ctx_window_size: ai_api_selector.get_agent_ctx_window_size
  get_agent_model: ai_api_selector.get_agent_model
  get_embedding_model: ai_api_selector.get_embedding_model
  InMemorySessionService: google.adk.sessions.InMemorySessionService
  InvocationContext: google.adk.agents.invocation_context.InvocationContext
  json: json
  LiteLlm: google.adk.models.lite_llm.LiteLlm
  LlmAgent: google.adk.agents.LlmAgent
  load_dotenv: dotenv.load_dotenv
  logging: logging
  OllamaEmbeddings: langchain_ollama.OllamaEmbeddings
  OpenAIEmbeddings: langchain_openai.OpenAIEmbeddings
  os: os
  override: typing_extensions.override
  Path: pathlib.Path
  pd: pandas
  pymupdf4llm: pymupdf4llm
  query_retriever: rag_pipeline.vector.query_retriever
  re: re
  reasoner_agent: agent.reasoner_agent
  root_agent: agent.root_agent
  Runner: google.adk.runners.Runner
  types: google.genai.types
  uuid: uuid
  vectorize_excel: rag_pipeline.vectorize_excel.vectorize_excel
  vectorize_pdf: rag_pipeline.vectorize_pdf.vectorize_pdf

functions:
  __init__:
    type: sync
    module: backend.src.city_agent.agent
    args: [self, name, data_fetcher, location_agent, math_analyst, reasoner_agent, validator_agent, output_agent]
  _is_english_header:
    type: sync
    module: backend.src.rag_pipeline.vectorize_excel
    args: [h]
    params:
      returns: bool
  _run_async_impl:
    type: async
    module: backend.src.city_agent.agent
    args: [self, ctx]
    params:
      returns: AsyncGenerator
  add_documents_to_vector_store:
    type: sync
    module: backend.src.rag_pipeline.vector
    args: [documents, ids, chunk_size]
  call_agent:
    type: async
    module: backend.src.rag_pipeline.vectorize_pdf
    args: [runner_instance, agent_instance, session_id, query]
  get_agent_ctx_window_size:
    type: sync
    module: backend.src.ai_api_selector
  get_agent_model:
    type: sync
    module: backend.src.ai_api_selector
    params:
      returns: LiteLlm
  get_embedding_model:
    type: sync
    module: backend.src.ai_api_selector
  get_or_create_session:
    type: async
    module: backend.src.rag_pipeline.vectorize_pdf
    args: [app_name, user_id, session_id]
  initialize_vector_store:
    type: async
    module: backend.src.rag_pipeline.vector
  load_data:
    type: async
    module: backend.src.rag_pipeline.vector
  query_retriever:
    type: sync
    module: backend.src.rag_pipeline.vector
    args: [query]
  search_data:
    type: async
    module: backend.src.city_agent.agent
    args: [query]
    params:
      returns: str
  vectorize_excel:
    type: async
    module: backend.src.rag_pipeline.vectorize_excel
    args: [filepath]
  vectorize_pdf:
    type: async
    module: backend.src.rag_pipeline.vectorize_pdf
    args: [filepath]

variables:
  AGENT_CTX_WINDOW_SIZE:
    type: env
    params:
      caller: [os.getenv]
      path: [backend.src.ai_api_selector]
  AI_API_PROVIDER:
    type: env
    params:
      caller: [os.getenv]
      path: [backend.src.ai_api_selector]
  AZURE_API_BASE_EMBEDDING:
    type: env
    params:
      caller: [os.getenv]
      path: [backend.src.ai_api_selector]
  AZURE_API_KEY_EMBEDDING:
    type: env
    params:
      caller: [os.getenv, AzureOpenAIEmbeddings]
      path: [backend.src.ai_api_selector]
  AZURE_API_VERSION_EMBEDDING:
    type: env
    params:
      caller: [os.getenv]
      path: [backend.src.ai_api_selector]
  OLLAMA_API_BASE:
    type: env
    params:
      caller: [os.environ, os.getenv]
      path: [backend.src.ai_api_selector]
  OPENAI_API_BASE:
    type: env
    params:
      caller: [os.getenv]
      path: [backend.src.ai_api_selector]
  OPENAI_API_KEY:
    type: env
    params:
      caller: [os.getenv, LiteLlm, OpenAIEmbeddings]
      path: [backend.src.ai_api_selector]

files:
  filepath:
    type: variable
    actions: [read]
    params:
      caller: [os.path.basename]
